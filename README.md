# Spatio-Temporal-3D-Reconstruction-from-Frame-Sequences-and-Feature-Points





## Citation

```
@inproceedings{10.1145/3672406.3672415,
author = {Federico, Giulio and Carrara, Fabio and Amato, Giuseppe and Di Benedetto, Marco},
title = {Spatio-Temporal 3D Reconstruction from Frame Sequences and Feature Points},
year = {2024},
isbn = {9798400717949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3672406.3672415},
doi = {10.1145/3672406.3672415},
abstract = {Reconstructing a large real environment is a fundamental task to promote eXtended Reality adoption in industrial and entertainment fields. However, the short range of depth cameras, the sparsity of LiDAR sensors, and the huge computational cost of Structure-from-Motion pipelines prevent scene replication in near real time. To overcome these limitations, we introduce a spatio-temporal diffusion neural architecture, a generative AI technique that fuses temporal information (i.e., a short temporally-ordered list of color photographs, like sparse frames of a video stream) with an approximate spatial resemblance of the explored environment. Our aim is to modify an existing 3D diffusion neural model to produce a Signed Distance Field volume from which a 3D mesh representation can be extracted. Our results show that the hallucination approach of diffusion models is an effective methodology where a fast reconstruction is a crucial target.},
booktitle = {Proceedings of the 2024 ACM International Conference on Interactive Media Experiences Workshops},
pages = {52â€“64},
numpages = {13},
keywords = {3D Reconstruction, Artificial Intelligence, Deep Learning, Denoising Diffusion Probabilistic Model, Machine Learning, Signed Distance Field, Video Reconstruction},
location = {Stockholm, Sweden},
series = {IMXw '24}
}
